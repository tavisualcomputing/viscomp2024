{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Quickstart for Google Colab\n",
    "from pathlib import Path\n",
    "if Path.cwd().name != 'W5':\n",
    "  !git clone --quiet https://github.com/tavisualcomputing/viscomp2024/\n",
    "  %cd viscomp2024/Solutions/W5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Week 5: PCA\n",
    "\n",
    "The exercise of this week is about PCA. Run this notebook on Colab [following this link](https://colab.research.google.com/github/tavisualcomputing/viscomp2024/blob/main/Solutions/W5/W5_exercise_sol.ipynb).\n",
    "\n",
    "First load the following libraries that will be necessary and extract the dataset archive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scipy\n",
    "!pip install scikit-image\n",
    "!pip install matplotlib\n",
    "!unzip -q ../../Exercises/W5/dataset.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from skimage.io import imread\n",
    "from scipy import signal,ndimage\n",
    "import numpy as np\n",
    "import time\n",
    "import scipy.io as sio\n",
    "from matplotlib.pyplot import imshow,show,figure\n",
    "import skimage.transform as tf\n",
    "import IPython\n",
    "import scipy\n",
    "from sys import getsizeof\n",
    "\n",
    "def make_grid(image_list,rows=5):\n",
    "    cols = len(image_list)//rows\n",
    "    row_image_list = []\n",
    "    for c in range(cols):\n",
    "        col_image_list = []\n",
    "        for r in range(rows):\n",
    "            col_image_list.append(image_list[c*rows+r])\n",
    "        col_image = np.concatenate(col_image_list,axis=0)\n",
    "        row_image_list.append(col_image)\n",
    "    return np.concatenate(row_image_list,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load images\n",
    "\n",
    "We use the AT&T dataset, which consists of 40 people with 10 experssions each. We split the dataset into two parts, training images and test images. The training images will be used to extract the eigenfaces, which are then used to compress test images.\n",
    "\n",
    "**First, we load the training data.** Here we take 5 expressions of 20 people as training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_person_ids = np.arange(1,21)\n",
    "train_expression_ids = np.arange(1,6)\n",
    "train_image_list = []\n",
    "for pid in train_person_ids:\n",
    "    for eid in train_expression_ids:\n",
    "        image = imread('dataset/s%d/%d.pgm'%(pid,eid))/255.\n",
    "        image = tf.rescale(image,0.6)\n",
    "        h,w = image.shape\n",
    "        train_image_list.append(image)\n",
    "\n",
    "train_image_collage = make_grid(train_image_list,rows=5)\n",
    "figure(dpi=200)\n",
    "imshow(train_image_collage,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Then we load the test images.** To see if the method can deal with unseen people and unseen expressions, we test with the rest 5 expressions of the rest 20 people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_person_ids = np.arange(21,38)\n",
    "test_expression_ids = np.arange(6,11)\n",
    "test_image_list = []\n",
    "for pid in test_person_ids:\n",
    "    for eid in test_expression_ids:\n",
    "        image = imread('dataset/s%d/%d.pgm'%(pid,eid))/255.\n",
    "        image = tf.rescale(image,0.6)\n",
    "        h,w = image.shape\n",
    "        test_image_list.append(image)\n",
    "        \n",
    "test_image_collage = make_grid(test_image_list,rows=5)\n",
    "figure(dpi=200)\n",
    "imshow(test_image_collage,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A: Image Compression\n",
    "\n",
    "In part A, we will use PCA to compress face images. For convenience we reshape the N training images into vectors of length $D = Height\\times Width$ and concatenate all vectors to form a $D \\times N$ matrix $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_vectors = [image.flatten() for image in train_image_list]\n",
    "X = np.stack(image_vectors, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute the mean and covariance of images.** The mean of images $\\mu$ is a vector of length $D$ and can be visualized as an image. The covariance $\\Sigma$ is a $D \\times D$ matrix. You can use `numpy.mean()` and `numpy.cov()` for the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = X.mean(1)\n",
    "imshow(mean.reshape(h,w),cmap='gray')\n",
    "\n",
    "centered_images = X - np.stack([mean]*X.shape[1],axis=1)\n",
    "covariance = np.cov(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute eigenfaces.** Eigenfaces are the eigenvectors correponding to k-largest eigenvalues of covariance matrix. You can use `scipy.sparse.linalg.eigs(mat,k)` to compute $k$ largest eigenvalues of $mat$ and corresponding eigenvectors $[u_1 ... u_k]$ . Note that this function returns complex valued results, which needs to be converted to real numbers using `numpy.real()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_eigenvectors = 200\n",
    "eigenvalues, eigenvectors = scipy.sparse.linalg.eigs(covariance,k=num_eigenvectors)\n",
    "eigenvectors = eigenvectors.real\n",
    "\n",
    "for eigenvector in eigenvectors.T:\n",
    "    imshow(eigenvector.reshape(h,w),cmap='gray')    \n",
    "    IPython.display.clear_output(True)\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we can use the computed eigenfaces to compress images.** Face images can be approximated by linear combinations of eigenfaces $x=\\mu + c_1 u_1 + c_2 u_2 + .... + c_k u_k$. Therefore, we can use the weights $[c_1 ... c_k]$ to record a image, instead of saving all pixels values. Each weight $c_i$ is the projection of the normalized image $\\tilde{x} = x-\\mu$ onto the corresponding eigenface $u_i$, which can be computed by dot product $c_i = \\tilde{x} \\cdot u_i$. \n",
    "\n",
    "To recover a image from its compression we can use  $x=\\mu + c_1 u_1 + c_2 u_2 + .... + c_k u_k$.\n",
    "\n",
    "\n",
    "**Complete the lines below to compress a image into a $k$ dimensional vector.**\n",
    "\n",
    "**Q:** Compress training images and test images. On which set the method works better? Why?\n",
    "\n",
    "**Q:** Compress image with different number of eigenfaces. What's the influence of $k$?\n",
    "\n",
    "**Q:** Considering that we want to reduce data size, what is the maximum value of $k$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_images = []\n",
    "for image in test_image_list[:]:\n",
    "    \n",
    "    # Compression\n",
    "    centered_image = image.flatten() - mean;\n",
    "    compressed_image = eigenvectors.T @ centered_image;\n",
    "    \n",
    "    # Decompression\n",
    "    centered_image = eigenvectors @ compressed_image\n",
    "    decompressed_image = centered_image + mean\n",
    "    \n",
    "    error_image = np.abs(decompressed_image-image.flatten())\n",
    "    error_images.append(error_image)\n",
    "\n",
    "    imshow(np.concatenate([image.reshape(h,w),\\\n",
    "                          decompressed_image.reshape(h,w),\\\n",
    "                          error_image.reshape(h,w)],axis=-1),cmap='gray')\n",
    "\n",
    "    IPython.display.clear_output(True)\n",
    "    show()\n",
    "    \n",
    "print('Size before compression: %d Bytes'%image.nbytes)\n",
    "print('Size after compression: %d Bytes'%compressed_image.nbytes)\n",
    "           \n",
    "error_images = np.stack(error_images,0)\n",
    "ssd_error = (error_images**2).sum(-1).mean()\n",
    "print(ssd_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B: Face Detection with PCA\n",
    "**In this part we will use PCA to detect faces.** In previous part, we have implemented a compressor for face images. Since the eigenvectors are extracted from faces images, we can expect that such a compressor would fail on other images, leading to erroneous decompression. This fact can be used for face detection.\n",
    "\n",
    "You are given an image with a face and your task is to find the location (x coordinate) of the face.\n",
    "Try to compress and then decompress each part of the image using the method in part A, and then compute the SSD error. Based on the SSD error, find the localtion (x coordinate) where the face is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "image = imread('FaceDetection.bmp')[:h,:]/255.\n",
    "h_,w_ = image.shape\n",
    "\n",
    "errors = []\n",
    "\n",
    "# iterate over each part of the image\n",
    "for x in range(w_-w):\n",
    "    image_crop = image[:,x:x+w].flatten()\n",
    "    \n",
    "    # Compression\n",
    "    centered_image = image_crop - mean;\n",
    "    compressed_image = eigenvectors.T @ centered_image;\n",
    "    \n",
    "    # Decompression\n",
    "    centered_image = eigenvectors @ compressed_image\n",
    "    decompressed_image = centered_image + mean\n",
    "\n",
    "    error = ((image_crop - decompressed_image)**2).sum()\n",
    "    errors.append(error)\n",
    "    \n",
    "    fig, ax = plt.subplots(2,1)\n",
    "    rect = patches.Rectangle((x,0),w,h,linewidth=3,edgecolor='r',facecolor='none')\n",
    "    ax[0].imshow(image,cmap='gray')\n",
    "    ax[0].add_patch(rect)\n",
    "    ax[1].plot(np.arange(x+1)+w//2,np.array(errors))\n",
    "    ax[1].set_xlim([0,w_])\n",
    "    IPython.display.clear_output(True)\n",
    "    show()\n",
    "\n",
    "x_best = np.argmin(errors)\n",
    "fig, ax = plt.subplots(2,1)\n",
    "rect = patches.Rectangle((x_best,0),w,h,linewidth=3,edgecolor='g',facecolor='none')\n",
    "\n",
    "ax[0].imshow(image,cmap='gray')\n",
    "ax[0].add_patch(rect)\n",
    "ax[1].plot(np.arange(x+1)+w//2,np.array(errors))\n",
    "ax[1].set_xlim([0,w_])\n",
    "IPython.display.clear_output(True)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part C: Exam question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt](exam_answer.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
